{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Submission Changed Strategy\n",
    "\n",
    "Here we make two sets of labels:\n",
    "One -> \"Raw\" and \"Ripe\"\n",
    "Two -> All the fruits\n",
    "\n",
    "We train different on both of these labels separately and predict values\n",
    "Then we concatenate the labels with an underscore to get our final prediction\n",
    "Accuracy on Submission: 67.25 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "      <th>4096</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.272801</td>\n",
       "      <td>0.290501</td>\n",
       "      <td>0.581446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.645888</td>\n",
       "      <td>0.86964</td>\n",
       "      <td>0.302432</td>\n",
       "      <td>0.953719</td>\n",
       "      <td>0.022545</td>\n",
       "      <td>0.498048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034988</td>\n",
       "      <td>0.692382</td>\n",
       "      <td>Orange_Ripe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.542096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.896557</td>\n",
       "      <td>0.049978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.50422</td>\n",
       "      <td>0.622686</td>\n",
       "      <td>0.588427</td>\n",
       "      <td>0.524415</td>\n",
       "      <td>0.305426</td>\n",
       "      <td>0.386204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.668196</td>\n",
       "      <td>Banana_Ripe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098595</td>\n",
       "      <td>0.571866</td>\n",
       "      <td>0.500355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.169341</td>\n",
       "      <td>0.913239</td>\n",
       "      <td>0.064404</td>\n",
       "      <td>0.53127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65825</td>\n",
       "      <td>Mango_Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101666</td>\n",
       "      <td>1.159194</td>\n",
       "      <td>0.599216</td>\n",
       "      <td>0.893206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200139</td>\n",
       "      <td>0</td>\n",
       "      <td>0.645675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560686</td>\n",
       "      <td>1.243676</td>\n",
       "      <td>0.432523</td>\n",
       "      <td>0.701881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.591165</td>\n",
       "      <td>Leeche_Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.178603</td>\n",
       "      <td>0.362568</td>\n",
       "      <td>0.577602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.079862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.206032</td>\n",
       "      <td>0.736831</td>\n",
       "      <td>0.345906</td>\n",
       "      <td>0.878515</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.261441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458905</td>\n",
       "      <td>Mango_Ripe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4097 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  0         1         2         3         4         5         6    7     \\\n",
       "0  0.0       0.0  1.272801  0.290501  0.581446       0.0       0.0    0   \n",
       "1  0.0       0.0  1.542096       0.0  0.896557  0.049978       0.0    0   \n",
       "2  0.0       0.0  1.098595  0.571866  0.500355       0.0       0.0    0   \n",
       "3  0.0  0.101666  1.159194  0.599216  0.893206       0.0  0.200139    0   \n",
       "4  0.0       0.0  1.178603  0.362568  0.577602       0.0       0.0    0   \n",
       "\n",
       "       8    9     ...      4087      4088      4089      4090      4091  \\\n",
       "0       0.0  0.0  ...  1.645888   0.86964  0.302432  0.953719  0.022545   \n",
       "1  0.117847  0.0  ...   1.50422  0.622686  0.588427  0.524415  0.305426   \n",
       "2  0.493137  0.0  ...  1.169341  0.913239  0.064404   0.53127       0.0   \n",
       "3  0.645675  0.0  ...  0.560686  1.243676  0.432523  0.701881       0.0   \n",
       "4  0.079862  0.0  ...  1.206032  0.736831  0.345906  0.878515     0.119   \n",
       "\n",
       "       4092 4093      4094      4095         4096  \n",
       "0  0.498048  0.0  0.034988  0.692382  Orange_Ripe  \n",
       "1  0.386204  0.0       0.0  0.668196  Banana_Ripe  \n",
       "2  0.471604  0.0       0.0   0.65825    Mango_Raw  \n",
       "3  0.589985  0.0       0.0  0.591165   Leeche_Raw  \n",
       "4  0.261441  0.0       0.0  0.458905   Mango_Ripe  \n",
       "\n",
       "[5 rows x 4097 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data from the file train.csv\n",
    "df = pd.read_csv('train.csv')\n",
    "data_matrix = np.array(df.values)\n",
    "\n",
    "# Drop the first column (id)\n",
    "data_matrix = np.delete(data_matrix, 0, 1)\n",
    "\n",
    "# Display as a table\n",
    "df_train = pd.DataFrame(data_matrix)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple_Raw' 'Apple_Ripe' 'Banana_Raw' 'Banana_Ripe' 'Coconut_Raw'\n",
      " 'Coconut_Ripe' 'Guava_Raw' 'Guava_Ripe' 'Leeche_Raw' 'Leeche_Ripe'\n",
      " 'Mango_Raw' 'Mango_Ripe' 'Orange_Raw' 'Orange_Ripe' 'Papaya_Raw'\n",
      " 'Papaya_Ripe' 'Pomengranate_Raw' 'Pomengranate_Ripe' 'Strawberry_Raw'\n",
      " 'Strawberry_Ripe']\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(data_matrix[:, -1]))\n",
    "print(len(np.unique(data_matrix[:, -1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ripe' 'Ripe' 'Raw' ... 'Ripe' 'Ripe' 'Ripe']\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing\n",
    "\n",
    "# We are going to divide the data into two sets of labels\n",
    "# First set will be 0 for Ripe and 1 for Raw\n",
    "# Second set will tell what fruit it is\n",
    "\n",
    "# First set of labels\n",
    "\n",
    "labels_first_set = data_matrix[:, -1].copy()\n",
    "for i in range(len(labels_first_set)):\n",
    "    if (labels_first_set[i] == 'Apple_Ripe' or labels_first_set[i] == 'Banana_Ripe' or labels_first_set[i] == 'Coconut_Ripe'\n",
    "        or labels_first_set[i] == 'Guava_Ripe' or labels_first_set[i] == 'Leeche_Ripe' or labels_first_set[i] == 'Mango_Ripe' or\n",
    "            labels_first_set[i] == 'Orange_Ripe' or labels_first_set[i] == 'Papaya_Ripe' or labels_first_set[i] == 'Pomegranate_Ripe' or\n",
    "                labels_first_set[i] == 'Strawberry_Ripe'):\n",
    "        labels_first_set[i] = 'Ripe'\n",
    "    else:\n",
    "        labels_first_set[i] = 'Raw'\n",
    "print(labels_first_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a logistic regression model\n",
    "lr_first = LogisticRegression()\n",
    "\n",
    "X_train = data_matrix[:, :-1]\n",
    "\n",
    "# Fit the model on the training data\n",
    "lr_first.fit(X_train, labels_first_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Orange' 'Banana' 'Mango' ... 'Banana' 'Guava' 'Guava']\n"
     ]
    }
   ],
   "source": [
    "# Now we will create a second set of labels\n",
    "# This will tell us what fruit it is\n",
    "\n",
    "labels_second_set = data_matrix[:, -1].copy()\n",
    "for i in range(len(labels_second_set)):\n",
    "    if(labels_second_set[i][0] == 'A'):\n",
    "        labels_second_set[i] = 'Apple'\n",
    "    elif(labels_second_set[i][0] == 'B'):\n",
    "        labels_second_set[i] = 'Banana'\n",
    "    elif(labels_second_set[i][0] == 'C'):\n",
    "        labels_second_set[i] = 'Coconut'\n",
    "    elif(labels_second_set[i][0] == 'G'):\n",
    "        labels_second_set[i] = 'Guava'\n",
    "    elif(labels_second_set[i][0] == 'L'):\n",
    "        labels_second_set[i] = 'Leeche'\n",
    "    elif(labels_second_set[i][0] == 'M'):\n",
    "        labels_second_set[i] = 'Mango'\n",
    "    elif(labels_second_set[i][0] == 'O'):\n",
    "        labels_second_set[i] = 'Orange'\n",
    "    elif(labels_second_set[i] == 'Papaya_Ripe' or labels_second_set[i] == 'Papaya_Raw'):\n",
    "        labels_second_set[i] = 'Papaya'\n",
    "    elif(labels_second_set[i][0] == 'P'):\n",
    "        labels_second_set[i] = 'Pomegranate'\n",
    "    else:\n",
    "        labels_second_set[i] = 'Strawberry'\n",
    "\n",
    "print(labels_second_set)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a logistic regression model\n",
    "lr_second = LogisticRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "lr_second.fit(X_train, labels_second_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.908889</td>\n",
       "      <td>0.251257</td>\n",
       "      <td>0.662262</td>\n",
       "      <td>0.042495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.964784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694072</td>\n",
       "      <td>1.146161</td>\n",
       "      <td>1.483842</td>\n",
       "      <td>0.717836</td>\n",
       "      <td>0.472616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.488022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.655670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.191055</td>\n",
       "      <td>0.407350</td>\n",
       "      <td>0.441898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273436</td>\n",
       "      <td>1.466932</td>\n",
       "      <td>0.940850</td>\n",
       "      <td>0.470344</td>\n",
       "      <td>1.032085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.654070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261903</td>\n",
       "      <td>0.992782</td>\n",
       "      <td>0.301102</td>\n",
       "      <td>0.636006</td>\n",
       "      <td>0.009558</td>\n",
       "      <td>0.009448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769983</td>\n",
       "      <td>0.834360</td>\n",
       "      <td>0.369656</td>\n",
       "      <td>1.000858</td>\n",
       "      <td>0.431571</td>\n",
       "      <td>0.361993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.392158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.352401</td>\n",
       "      <td>0.346003</td>\n",
       "      <td>0.401412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.450667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339935</td>\n",
       "      <td>1.325595</td>\n",
       "      <td>0.981124</td>\n",
       "      <td>0.486731</td>\n",
       "      <td>0.747392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.628365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.114281</td>\n",
       "      <td>0.696140</td>\n",
       "      <td>0.121505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.591384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093661</td>\n",
       "      <td>0.875113</td>\n",
       "      <td>0.360689</td>\n",
       "      <td>0.659230</td>\n",
       "      <td>0.546044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.835671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1         2         3         4         5         6     7     \\\n",
       "0   0.0  0.000000  0.908889  0.251257  0.662262  0.042495  0.000000   0.0   \n",
       "1   0.0  0.000000  1.191055  0.407350  0.441898  0.000000  0.334858   0.0   \n",
       "2   0.0  0.261903  0.992782  0.301102  0.636006  0.009558  0.009448   0.0   \n",
       "3   0.0  0.000000  1.352401  0.346003  0.401412  0.000000  0.000000   0.0   \n",
       "4   0.0  0.000000  1.114281  0.696140  0.121505  0.000000  0.000000   0.0   \n",
       "\n",
       "       8     9     ...      4086      4087      4088      4089      4090  \\\n",
       "0  0.964784   0.0  ...  0.694072  1.146161  1.483842  0.717836  0.472616   \n",
       "1  0.295357   0.0  ...  0.273436  1.466932  0.940850  0.470344  1.032085   \n",
       "2  0.974949   0.0  ...  0.000000  0.769983  0.834360  0.369656  1.000858   \n",
       "3  0.450667   0.0  ...  0.339935  1.325595  0.981124  0.486731  0.747392   \n",
       "4  0.591384   0.0  ...  0.093661  0.875113  0.360689  0.659230  0.546044   \n",
       "\n",
       "       4091      4092  4093  4094      4095  \n",
       "0  0.000000  0.488022   0.0   0.0  0.655670  \n",
       "1  0.000000  0.654070   0.0   0.0  0.614493  \n",
       "2  0.431571  0.361993   0.0   0.0  0.392158  \n",
       "3  0.000000  0.300671   0.0   0.0  0.628365  \n",
       "4  0.000000  0.427255   0.0   0.0  0.835671  \n",
       "\n",
       "[5 rows x 4096 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opening the test file for the test data\n",
    "df_test = pd.read_csv('test.csv')\n",
    "data_matrix_test = np.array(df_test.values)\n",
    "\n",
    "# Drop the first column (id)\n",
    "data_matrix_test = np.delete(data_matrix_test, 0, 1)\n",
    "\n",
    "# Display as a table\n",
    "df_test = pd.DataFrame(data_matrix_test)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_matrix_test.copy()\n",
    "\n",
    "# Predicting the labels for the test data from the first set of labels\n",
    "y_pred_first = lr_first.predict(X_test)\n",
    "\n",
    "# Predicting the labels for the test data from the second set of labels\n",
    "y_pred_second = lr_second.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for every label we generated in the first and second set, we combine them with an underscore to get the final label\n",
    "# We will use this to compare with the actual labels\n",
    "\n",
    "y_pred =  y_pred_second + '_' + y_pred_first\n",
    "\n",
    "# Now we will save these predictions in a csv file with the id and the predicted label\n",
    "# We will also calculate the accuracy of our model\n",
    "\n",
    "# Opening the file to write the predictions\n",
    "file = open('predictions.csv', 'w')\n",
    "\n",
    "# Writing the header\n",
    "file.write('id,label')\n",
    "for i in range(len(y_pred)):\n",
    "    file.write('\\n')\n",
    "    file.write(str(i))\n",
    "    file.write(',')\n",
    "    file.write(y_pred[i])\n",
    "\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
