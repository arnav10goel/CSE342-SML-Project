{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import hdbscan\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Import Fuzzy c means clustering\n",
    "# from fcmeans import FCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "      <th>4096</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.272801</td>\n",
       "      <td>0.290501</td>\n",
       "      <td>0.581446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.645888</td>\n",
       "      <td>0.86964</td>\n",
       "      <td>0.302432</td>\n",
       "      <td>0.953719</td>\n",
       "      <td>0.022545</td>\n",
       "      <td>0.498048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034988</td>\n",
       "      <td>0.692382</td>\n",
       "      <td>Orange_Ripe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.542096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.896557</td>\n",
       "      <td>0.049978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.50422</td>\n",
       "      <td>0.622686</td>\n",
       "      <td>0.588427</td>\n",
       "      <td>0.524415</td>\n",
       "      <td>0.305426</td>\n",
       "      <td>0.386204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.668196</td>\n",
       "      <td>Banana_Ripe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098595</td>\n",
       "      <td>0.571866</td>\n",
       "      <td>0.500355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.169341</td>\n",
       "      <td>0.913239</td>\n",
       "      <td>0.064404</td>\n",
       "      <td>0.53127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65825</td>\n",
       "      <td>Mango_Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101666</td>\n",
       "      <td>1.159194</td>\n",
       "      <td>0.599216</td>\n",
       "      <td>0.893206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.645675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560686</td>\n",
       "      <td>1.243676</td>\n",
       "      <td>0.432523</td>\n",
       "      <td>0.701881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.591165</td>\n",
       "      <td>Leeche_Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.178603</td>\n",
       "      <td>0.362568</td>\n",
       "      <td>0.577602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.206032</td>\n",
       "      <td>0.736831</td>\n",
       "      <td>0.345906</td>\n",
       "      <td>0.878515</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.261441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458905</td>\n",
       "      <td>Mango_Ripe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4097 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  0         1         2         3         4         5         6    7     \\\n",
       "0  0.0       0.0  1.272801  0.290501  0.581446       0.0       0.0  0.0   \n",
       "1  0.0       0.0  1.542096       0.0  0.896557  0.049978       0.0  0.0   \n",
       "2  0.0       0.0  1.098595  0.571866  0.500355       0.0       0.0  0.0   \n",
       "3  0.0  0.101666  1.159194  0.599216  0.893206       0.0  0.200139  0.0   \n",
       "4  0.0       0.0  1.178603  0.362568  0.577602       0.0       0.0  0.0   \n",
       "\n",
       "       8    9     ...      4087      4088      4089      4090      4091  \\\n",
       "0       0.0  0.0  ...  1.645888   0.86964  0.302432  0.953719  0.022545   \n",
       "1  0.117847  0.0  ...   1.50422  0.622686  0.588427  0.524415  0.305426   \n",
       "2  0.493137  0.0  ...  1.169341  0.913239  0.064404   0.53127       0.0   \n",
       "3  0.645675  0.0  ...  0.560686  1.243676  0.432523  0.701881       0.0   \n",
       "4  0.079862  0.0  ...  1.206032  0.736831  0.345906  0.878515     0.119   \n",
       "\n",
       "       4092 4093      4094      4095         4096  \n",
       "0  0.498048  0.0  0.034988  0.692382  Orange_Ripe  \n",
       "1  0.386204  0.0       0.0  0.668196  Banana_Ripe  \n",
       "2  0.471604  0.0       0.0   0.65825    Mango_Raw  \n",
       "3  0.589985  0.0       0.0  0.591165   Leeche_Raw  \n",
       "4  0.261441  0.0       0.0  0.458905   Mango_Ripe  \n",
       "\n",
       "[5 rows x 4097 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data from the file train.csv\n",
    "df = pd.read_csv('train.csv')\n",
    "data_matrix = np.array(df.values)\n",
    "\n",
    "# Drop the first column (id)\n",
    "data_matrix = np.delete(data_matrix, 0, 1)\n",
    "\n",
    "# Display as a table\n",
    "df_train = pd.DataFrame(data_matrix)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers:  6\n"
     ]
    }
   ],
   "source": [
    "# Import local outlier factor\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# Create a local outlier factor object\n",
    "lof = LocalOutlierFactor(n_neighbors=9)\n",
    "\n",
    "# Predict the outliers\n",
    "outliers = lof.fit_predict(data_matrix[:, :-1])\n",
    "\n",
    "# Print the number of outliers\n",
    "print('Number of outliers: ', np.count_nonzero(outliers == -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1217, 4097)\n",
      "(1211, 4097)\n"
     ]
    }
   ],
   "source": [
    "print(data_matrix.shape)\n",
    "\n",
    "# Remove outliers\n",
    "data_matrix = data_matrix[outliers != -1]\n",
    "\n",
    "print(data_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.908889</td>\n",
       "      <td>0.251257</td>\n",
       "      <td>0.662262</td>\n",
       "      <td>0.042495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.964784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694072</td>\n",
       "      <td>1.146161</td>\n",
       "      <td>1.483842</td>\n",
       "      <td>0.717836</td>\n",
       "      <td>0.472616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.488022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.655670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.191055</td>\n",
       "      <td>0.407350</td>\n",
       "      <td>0.441898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273436</td>\n",
       "      <td>1.466932</td>\n",
       "      <td>0.940850</td>\n",
       "      <td>0.470344</td>\n",
       "      <td>1.032085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.654070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261903</td>\n",
       "      <td>0.992782</td>\n",
       "      <td>0.301102</td>\n",
       "      <td>0.636006</td>\n",
       "      <td>0.009558</td>\n",
       "      <td>0.009448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769983</td>\n",
       "      <td>0.834360</td>\n",
       "      <td>0.369656</td>\n",
       "      <td>1.000858</td>\n",
       "      <td>0.431571</td>\n",
       "      <td>0.361993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.392158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.352401</td>\n",
       "      <td>0.346003</td>\n",
       "      <td>0.401412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.450667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339935</td>\n",
       "      <td>1.325595</td>\n",
       "      <td>0.981124</td>\n",
       "      <td>0.486731</td>\n",
       "      <td>0.747392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.628365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.114281</td>\n",
       "      <td>0.696140</td>\n",
       "      <td>0.121505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.591384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093661</td>\n",
       "      <td>0.875113</td>\n",
       "      <td>0.360689</td>\n",
       "      <td>0.659230</td>\n",
       "      <td>0.546044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.835671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1         2         3         4         5         6     7     \\\n",
       "0   0.0  0.000000  0.908889  0.251257  0.662262  0.042495  0.000000   0.0   \n",
       "1   0.0  0.000000  1.191055  0.407350  0.441898  0.000000  0.334858   0.0   \n",
       "2   0.0  0.261903  0.992782  0.301102  0.636006  0.009558  0.009448   0.0   \n",
       "3   0.0  0.000000  1.352401  0.346003  0.401412  0.000000  0.000000   0.0   \n",
       "4   0.0  0.000000  1.114281  0.696140  0.121505  0.000000  0.000000   0.0   \n",
       "\n",
       "       8     9     ...      4086      4087      4088      4089      4090  \\\n",
       "0  0.964784   0.0  ...  0.694072  1.146161  1.483842  0.717836  0.472616   \n",
       "1  0.295357   0.0  ...  0.273436  1.466932  0.940850  0.470344  1.032085   \n",
       "2  0.974949   0.0  ...  0.000000  0.769983  0.834360  0.369656  1.000858   \n",
       "3  0.450667   0.0  ...  0.339935  1.325595  0.981124  0.486731  0.747392   \n",
       "4  0.591384   0.0  ...  0.093661  0.875113  0.360689  0.659230  0.546044   \n",
       "\n",
       "       4091      4092  4093  4094      4095  \n",
       "0  0.000000  0.488022   0.0   0.0  0.655670  \n",
       "1  0.000000  0.654070   0.0   0.0  0.614493  \n",
       "2  0.431571  0.361993   0.0   0.0  0.392158  \n",
       "3  0.000000  0.300671   0.0   0.0  0.628365  \n",
       "4  0.000000  0.427255   0.0   0.0  0.835671  \n",
       "\n",
       "[5 rows x 4096 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opening the test file for the test data\n",
    "df_test = pd.read_csv('test.csv')\n",
    "data_matrix_test = np.array(df_test.values)\n",
    "\n",
    "# Drop the first column (id)\n",
    "data_matrix_test = np.delete(data_matrix_test, 0, 1)\n",
    "\n",
    "# Display as a table\n",
    "df_test = pd.DataFrame(data_matrix_test)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1211, 4096)\n",
      "(415, 4096)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_matrix[:, :-1].copy()\n",
    "y_train = data_matrix[:, -1].copy()\n",
    "\n",
    "X_test = data_matrix_test.copy()\n",
    "\n",
    "# #Scale the data\n",
    "# sc = StandardScaler()\n",
    "\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "\n",
    "# X_test = sc.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform KMeans clustering\n",
    "\n",
    "# #Number of clusters\n",
    "# k = 20\n",
    "# # Create a KMeans instance with k clusters: model\n",
    "# model = KMeans(random_state=0, n_clusters=k)\n",
    "\n",
    "# # Fit model to samples\n",
    "# model.fit(X_train)\n",
    "\n",
    "# # Determine the cluster labels of new_points: labels\n",
    "# labels = model.predict(X_train)\n",
    "\n",
    "# # Print the silhouette score\n",
    "# print(silhouette_score(X_train, labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Add the cluster labels to X_train as an additional column\n",
    "# X_train = np.insert(X_train, 0, labels, axis=1)\n",
    "\n",
    "# # Display as a table\n",
    "# df_train = pd.DataFrame(X_train)\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Apply the same clustering to test data\n",
    "\n",
    "# # Determine the cluster labels of new_points: labels\n",
    "# labels_test = model.predict(X_test)\n",
    "\n",
    "# # Add the cluster labels to the data matrix as the first column\n",
    "# X_test = np.insert(X_test, 0, labels_test, axis=1)\n",
    "\n",
    "# # Display as a table\n",
    "# df_test = pd.DataFrame(X_test)\n",
    "# df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform fuzzy c-means clustering\n",
    "# fuzzy_model = FCM(n_clusters=20)\n",
    "\n",
    "# # Fit the fuzzy model to the training data\n",
    "# fuzzy_model.fit(X_train)\n",
    "\n",
    "# # Extract the cluster labels\n",
    "# labels = fuzzy_model.u.argmax(axis=1)\n",
    "\n",
    "# # Print the silhouette score\n",
    "# print(silhouette_score(X_train, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add the cluster labels to X_train as an additional column\n",
    "# X_train = np.insert(X_train, 0, labels, axis=1)\n",
    "\n",
    "# # Display as a table\n",
    "# df_train = pd.DataFrame(X_train)\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the same clustering to test data\n",
    "\n",
    "# Extract the cluster labels\n",
    "# labels_test = fuzzy_model.predict(X_test)\n",
    "\n",
    "# # Add the cluster labels to the data matrix as the first column\n",
    "# X_test = np.insert(X_test, 0, labels_test, axis=1)\n",
    "\n",
    "# # Display as a table\n",
    "# df_test = pd.DataFrame(X_test)\n",
    "# df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the X_train and y_train into training and validation sets\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=0)\n",
    "\n",
    "X_train = X_train2.copy()\n",
    "y_train = y_train2.copy()\n",
    "X_test = X_val.copy()\n",
    "y_test = y_val.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Implement Grid Search to find Best Features\n",
    "\n",
    "# random_state = [0, 10, 30, 42, 60, 80]\n",
    "# pcs = [100, 150, 200, 250, 300, 400]\n",
    "\n",
    "# for r in random_state:\n",
    "#     for p in pcs:\n",
    "#         print('Random State: ', r)\n",
    "#         print('Number of Principal Components: ', p)\n",
    "#         # Split the X_train and y_train into training and validation sets\n",
    "#         X_train2, X_val, y_train2, y_val = train_test_split(X_train_og, y_train_og, test_size=0.2, random_state=r)\n",
    "\n",
    "#         X_train = X_train2.copy()\n",
    "#         y_train = y_train2.copy()\n",
    "#         X_test = X_val.copy()\n",
    "#         y_test = y_val.copy()\n",
    "        \n",
    "#         # Create a PCA object\n",
    "#         pca = PCA(n_components=p)\n",
    "\n",
    "#         # Fit the PCA object to the training data\n",
    "#         pca.fit(X_train)\n",
    "\n",
    "#         # Transform the training data\n",
    "#         X_train = pca.transform(X_train)\n",
    "\n",
    "#         # Transform the test data\n",
    "#         X_test = pca.transform(X_test)\n",
    "\n",
    "#         # Apply LDA\n",
    "#         lda = LDA(n_components=19, tol=1e-5)\n",
    "\n",
    "#         lda.fit(X_train, y_train)\n",
    "\n",
    "#         # Transform the training data\n",
    "#         X_train = lda.transform(X_train)\n",
    "\n",
    "#         # Transform the test data\n",
    "#         X_test = lda.transform(X_test)\n",
    "\n",
    "#         # Import LogisticRegression\n",
    "#         from sklearn.linear_model import LogisticRegression\n",
    "#         from sklearn import metrics\n",
    "\n",
    "#         # Create a logistic regression object\n",
    "#         logreg = LogisticRegression(max_iter=3000, solver='lbfgs', multi_class='multinomial', random_state=0)\n",
    "\n",
    "#         # Train the model using the training sets\n",
    "#         logreg.fit(X_train, y_train)\n",
    "\n",
    "#         # Predict the response for validation set\n",
    "#         y_pred = logreg.predict(X_test)\n",
    "\n",
    "#         # Model Accuracy, how often is the classifier correct?\n",
    "#         print(\"LR Validation Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PCA object\n",
    "pca = PCA(n_components=360)\n",
    "\n",
    "# Fit the PCA object to the training data\n",
    "pca.fit(X_train)\n",
    "\n",
    "# Transform the training data\n",
    "X_train = pca.transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LDA\n",
    "lda = LDA(n_components=19)\n",
    "\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "# Transform the training data\n",
    "X_train = lda.transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test = lda.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# Create a logistic regression object\n",
    "logreg = LogisticRegression(multi_class='multinomial',solver='newton-cg',max_iter=1000)\n",
    "\n",
    "# Train the model using the training sets\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for validation set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# # Model Accuracy, how often is the classifier correct?\n",
    "# print(\"Validation Accuracy:\",metrics.accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Opening the file to write the predictions\n",
    "# file = open('LOF_PCA_LDA_LR.csv', 'w')\n",
    "\n",
    "# # Writing the header\n",
    "# file.write('ID,Category')\n",
    "# for i in range(len(y_pred)):\n",
    "#     file.write('\\n')\n",
    "#     file.write(str(i))\n",
    "#     file.write(',')\n",
    "#     file.write(y_pred[i])\n",
    "\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7986798679867987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, bootstrap=False, max_depth=90, min_samples_leaf=3, min_samples_split=6, n_jobs=-1, random_state=0, verbose=1)\n",
    "\n",
    "# Train the classifier\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the validation set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Opening the file to write the predictions\n",
    "# file = open('RFC_LDA_PCA_LOF.csv', 'w')\n",
    "\n",
    "# # Writing the header\n",
    "# file.write('ID,Category')\n",
    "# for i in range(len(y_pred)):\n",
    "#     file.write('\\n')\n",
    "#     file.write(str(i))\n",
    "#     file.write(',')\n",
    "#     file.write(y_pred[i])\n",
    "\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a Bagging Classifier\n",
    "# from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# # Train the classifier\n",
    "# bag_clf = BaggingClassifier(base_estimator=rf, n_estimators=100, bootstrap=True, n_jobs=-1, random_state=0, verbose=1)\n",
    "\n",
    "# bag_clf.fit(X_train2, y_train2)\n",
    "\n",
    "# # Predict the validation set\n",
    "# y_pred = bag_clf.predict(X_val)\n",
    "\n",
    "# # Calculate the accuracy\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.801980198019802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Import ADA Boosting Classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Create adaboost classifer object\n",
    "abc = AdaBoostClassifier(base_estimator=rf, n_estimators=400, learning_rate=0.01, random_state=0)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "model = abc.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for validation set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Validation Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n",
    "\n",
    "# # Opening the file to write the predictions\n",
    "# file = open('LOF_RFC_ADA.csv', 'w')\n",
    "\n",
    "# # Writing the header\n",
    "# file.write('ID,Category')\n",
    "# for i in range(len(y_pred)):\n",
    "#     file.write('\\n')\n",
    "#     file.write(str(i))\n",
    "#     file.write(',')\n",
    "#     file.write(y_pred[i])\n",
    "\n",
    "# file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    9.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    9.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    9.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    9.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    9.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    9.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    9.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   10.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    9.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   10.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8118811881188119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Import Stack Classifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# define the base models\n",
    "level0 = list()\n",
    "\n",
    "level0.append(('logreg', logreg))\n",
    "level0.append(('rf', rf))\n",
    "level0.append(('abc', abc))\n",
    "\n",
    "# define meta learner model\n",
    "level1 = logreg\n",
    "\n",
    "# define the stacking ensemble\n",
    "model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5, n_jobs=-1, passthrough=True)\n",
    "\n",
    "# fit the model on all available data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for validation set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Validation Accuracy:\",metrics.accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Opening the file to write the predictions\n",
    "# file = open('output.csv', 'w')\n",
    "\n",
    "# # Writing the header\n",
    "# file.write('ID,Category')\n",
    "# for i in range(len(y_pred)):\n",
    "#     file.write('\\n')\n",
    "#     file.write(str(i))\n",
    "#     file.write(',')\n",
    "#     file.write(y_pred[i])\n",
    "\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create a Gradient Boosting Classifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# # Create a Gradient Boosting model\n",
    "# gb = GradientBoostingClassifier(n_estimators=400, learning_rate=0.01, max_depth=3, random_state=0, verbose=1)\n",
    "\n",
    "# # Fit the model to the training data\n",
    "# gb.fit(X_train, y_train)\n",
    "\n",
    "# #Predict the labels of the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = gb.predict(X_test)\n",
    "\n",
    "# # Calculate the accuracy of the model\n",
    "# accuracy = np.sum(y_pred == y_val) / len(y_val)\n",
    "\n",
    "# print('Validation Accuracy: ', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
