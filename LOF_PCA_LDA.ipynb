{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import hdbscan\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Import Fuzzy c means clustering\n",
    "from fcmeans import FCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "      <th>4096</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.272801</td>\n",
       "      <td>0.290501</td>\n",
       "      <td>0.581446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.645888</td>\n",
       "      <td>0.86964</td>\n",
       "      <td>0.302432</td>\n",
       "      <td>0.953719</td>\n",
       "      <td>0.022545</td>\n",
       "      <td>0.498048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034988</td>\n",
       "      <td>0.692382</td>\n",
       "      <td>Orange_Ripe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.542096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.896557</td>\n",
       "      <td>0.049978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.50422</td>\n",
       "      <td>0.622686</td>\n",
       "      <td>0.588427</td>\n",
       "      <td>0.524415</td>\n",
       "      <td>0.305426</td>\n",
       "      <td>0.386204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.668196</td>\n",
       "      <td>Banana_Ripe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098595</td>\n",
       "      <td>0.571866</td>\n",
       "      <td>0.500355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.169341</td>\n",
       "      <td>0.913239</td>\n",
       "      <td>0.064404</td>\n",
       "      <td>0.53127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65825</td>\n",
       "      <td>Mango_Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101666</td>\n",
       "      <td>1.159194</td>\n",
       "      <td>0.599216</td>\n",
       "      <td>0.893206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.645675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560686</td>\n",
       "      <td>1.243676</td>\n",
       "      <td>0.432523</td>\n",
       "      <td>0.701881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.591165</td>\n",
       "      <td>Leeche_Raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.178603</td>\n",
       "      <td>0.362568</td>\n",
       "      <td>0.577602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.206032</td>\n",
       "      <td>0.736831</td>\n",
       "      <td>0.345906</td>\n",
       "      <td>0.878515</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.261441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458905</td>\n",
       "      <td>Mango_Ripe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4097 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  0         1         2         3         4         5         6    7     \\\n",
       "0  0.0       0.0  1.272801  0.290501  0.581446       0.0       0.0  0.0   \n",
       "1  0.0       0.0  1.542096       0.0  0.896557  0.049978       0.0  0.0   \n",
       "2  0.0       0.0  1.098595  0.571866  0.500355       0.0       0.0  0.0   \n",
       "3  0.0  0.101666  1.159194  0.599216  0.893206       0.0  0.200139  0.0   \n",
       "4  0.0       0.0  1.178603  0.362568  0.577602       0.0       0.0  0.0   \n",
       "\n",
       "       8    9     ...      4087      4088      4089      4090      4091  \\\n",
       "0       0.0  0.0  ...  1.645888   0.86964  0.302432  0.953719  0.022545   \n",
       "1  0.117847  0.0  ...   1.50422  0.622686  0.588427  0.524415  0.305426   \n",
       "2  0.493137  0.0  ...  1.169341  0.913239  0.064404   0.53127       0.0   \n",
       "3  0.645675  0.0  ...  0.560686  1.243676  0.432523  0.701881       0.0   \n",
       "4  0.079862  0.0  ...  1.206032  0.736831  0.345906  0.878515     0.119   \n",
       "\n",
       "       4092 4093      4094      4095         4096  \n",
       "0  0.498048  0.0  0.034988  0.692382  Orange_Ripe  \n",
       "1  0.386204  0.0       0.0  0.668196  Banana_Ripe  \n",
       "2  0.471604  0.0       0.0   0.65825    Mango_Raw  \n",
       "3  0.589985  0.0       0.0  0.591165   Leeche_Raw  \n",
       "4  0.261441  0.0       0.0  0.458905   Mango_Ripe  \n",
       "\n",
       "[5 rows x 4097 columns]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data from the file train.csv\n",
    "df = pd.read_csv('train.csv')\n",
    "data_matrix = np.array(df.values)\n",
    "\n",
    "# Drop the first column (id)\n",
    "data_matrix = np.delete(data_matrix, 0, 1)\n",
    "\n",
    "# Display as a table\n",
    "df_train = pd.DataFrame(data_matrix)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers:  6\n"
     ]
    }
   ],
   "source": [
    "# Import local outlier factor\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# Create a local outlier factor object\n",
    "lof = LocalOutlierFactor(n_neighbors=9)\n",
    "\n",
    "# Predict the outliers\n",
    "outliers = lof.fit_predict(data_matrix[:, :-1])\n",
    "\n",
    "# Print the number of outliers\n",
    "print('Number of outliers: ', np.count_nonzero(outliers == -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1217, 4097)\n",
      "(1211, 4097)\n"
     ]
    }
   ],
   "source": [
    "print(data_matrix.shape)\n",
    "\n",
    "# Remove outliers\n",
    "data_matrix = data_matrix[outliers != -1]\n",
    "\n",
    "print(data_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.908889</td>\n",
       "      <td>0.251257</td>\n",
       "      <td>0.662262</td>\n",
       "      <td>0.042495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.964784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694072</td>\n",
       "      <td>1.146161</td>\n",
       "      <td>1.483842</td>\n",
       "      <td>0.717836</td>\n",
       "      <td>0.472616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.488022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.655670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.191055</td>\n",
       "      <td>0.407350</td>\n",
       "      <td>0.441898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273436</td>\n",
       "      <td>1.466932</td>\n",
       "      <td>0.940850</td>\n",
       "      <td>0.470344</td>\n",
       "      <td>1.032085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.654070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261903</td>\n",
       "      <td>0.992782</td>\n",
       "      <td>0.301102</td>\n",
       "      <td>0.636006</td>\n",
       "      <td>0.009558</td>\n",
       "      <td>0.009448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769983</td>\n",
       "      <td>0.834360</td>\n",
       "      <td>0.369656</td>\n",
       "      <td>1.000858</td>\n",
       "      <td>0.431571</td>\n",
       "      <td>0.361993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.392158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.352401</td>\n",
       "      <td>0.346003</td>\n",
       "      <td>0.401412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.450667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339935</td>\n",
       "      <td>1.325595</td>\n",
       "      <td>0.981124</td>\n",
       "      <td>0.486731</td>\n",
       "      <td>0.747392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.628365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.114281</td>\n",
       "      <td>0.696140</td>\n",
       "      <td>0.121505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.591384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093661</td>\n",
       "      <td>0.875113</td>\n",
       "      <td>0.360689</td>\n",
       "      <td>0.659230</td>\n",
       "      <td>0.546044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.835671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1         2         3         4         5         6     7     \\\n",
       "0   0.0  0.000000  0.908889  0.251257  0.662262  0.042495  0.000000   0.0   \n",
       "1   0.0  0.000000  1.191055  0.407350  0.441898  0.000000  0.334858   0.0   \n",
       "2   0.0  0.261903  0.992782  0.301102  0.636006  0.009558  0.009448   0.0   \n",
       "3   0.0  0.000000  1.352401  0.346003  0.401412  0.000000  0.000000   0.0   \n",
       "4   0.0  0.000000  1.114281  0.696140  0.121505  0.000000  0.000000   0.0   \n",
       "\n",
       "       8     9     ...      4086      4087      4088      4089      4090  \\\n",
       "0  0.964784   0.0  ...  0.694072  1.146161  1.483842  0.717836  0.472616   \n",
       "1  0.295357   0.0  ...  0.273436  1.466932  0.940850  0.470344  1.032085   \n",
       "2  0.974949   0.0  ...  0.000000  0.769983  0.834360  0.369656  1.000858   \n",
       "3  0.450667   0.0  ...  0.339935  1.325595  0.981124  0.486731  0.747392   \n",
       "4  0.591384   0.0  ...  0.093661  0.875113  0.360689  0.659230  0.546044   \n",
       "\n",
       "       4091      4092  4093  4094      4095  \n",
       "0  0.000000  0.488022   0.0   0.0  0.655670  \n",
       "1  0.000000  0.654070   0.0   0.0  0.614493  \n",
       "2  0.431571  0.361993   0.0   0.0  0.392158  \n",
       "3  0.000000  0.300671   0.0   0.0  0.628365  \n",
       "4  0.000000  0.427255   0.0   0.0  0.835671  \n",
       "\n",
       "[5 rows x 4096 columns]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opening the test file for the test data\n",
    "df_test = pd.read_csv('test.csv')\n",
    "data_matrix_test = np.array(df_test.values)\n",
    "\n",
    "# Drop the first column (id)\n",
    "data_matrix_test = np.delete(data_matrix_test, 0, 1)\n",
    "\n",
    "# Display as a table\n",
    "df_test = pd.DataFrame(data_matrix_test)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1211, 4096)\n",
      "(415, 4096)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_matrix[:, :-1].copy()\n",
    "y_train = data_matrix[:, -1].copy()\n",
    "\n",
    "X_test = data_matrix_test.copy()\n",
    "\n",
    "#Scale the data\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform KMeans clustering\n",
    "\n",
    "# #Number of clusters\n",
    "# k = 20\n",
    "# # Create a KMeans instance with k clusters: model\n",
    "# model = KMeans(random_state=0, n_clusters=k)\n",
    "\n",
    "# # Fit model to samples\n",
    "# model.fit(X_train)\n",
    "\n",
    "# # Determine the cluster labels of new_points: labels\n",
    "# labels = model.predict(X_train)\n",
    "\n",
    "# # Print the silhouette score\n",
    "# print(silhouette_score(X_train, labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Add the cluster labels to X_train as an additional column\n",
    "# X_train = np.insert(X_train, 0, labels, axis=1)\n",
    "\n",
    "# # Display as a table\n",
    "# df_train = pd.DataFrame(X_train)\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Apply the same clustering to test data\n",
    "\n",
    "# # Determine the cluster labels of new_points: labels\n",
    "# labels_test = model.predict(X_test)\n",
    "\n",
    "# # Add the cluster labels to the data matrix as the first column\n",
    "# X_test = np.insert(X_test, 0, labels_test, axis=1)\n",
    "\n",
    "# # Display as a table\n",
    "# df_test = pd.DataFrame(X_test)\n",
    "# df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform fuzzy c-means clustering\n",
    "# fuzzy_model = FCM(n_clusters=20)\n",
    "\n",
    "# # Fit the fuzzy model to the training data\n",
    "# fuzzy_model.fit(X_train)\n",
    "\n",
    "# # Extract the cluster labels\n",
    "# labels = fuzzy_model.u.argmax(axis=1)\n",
    "\n",
    "# # Print the silhouette score\n",
    "# print(silhouette_score(X_train, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add the cluster labels to X_train as an additional column\n",
    "# X_train = np.insert(X_train, 0, labels, axis=1)\n",
    "\n",
    "# # Display as a table\n",
    "# df_train = pd.DataFrame(X_train)\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the same clustering to test data\n",
    "\n",
    "# Extract the cluster labels\n",
    "# labels_test = fuzzy_model.predict(X_test)\n",
    "\n",
    "# # Add the cluster labels to the data matrix as the first column\n",
    "# X_test = np.insert(X_test, 0, labels_test, axis=1)\n",
    "\n",
    "# # Display as a table\n",
    "# df_test = pd.DataFrame(X_test)\n",
    "# df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the X_train and y_train into training and validation sets\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=0)\n",
    "\n",
    "X_train = X_train2.copy()\n",
    "y_train = y_train2.copy()\n",
    "X_test = X_val.copy()\n",
    "y_test = y_val.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Implement Grid Search to find Best Features\n",
    "\n",
    "# random_state = [0, 10, 30, 42, 60, 80]\n",
    "# pcs = [100, 150, 200, 250, 300, 400]\n",
    "\n",
    "# for r in random_state:\n",
    "#     for p in pcs:\n",
    "#         print('Random State: ', r)\n",
    "#         print('Number of Principal Components: ', p)\n",
    "#         # Split the X_train and y_train into training and validation sets\n",
    "#         X_train2, X_val, y_train2, y_val = train_test_split(X_train_og, y_train_og, test_size=0.2, random_state=r)\n",
    "\n",
    "#         X_train = X_train2.copy()\n",
    "#         y_train = y_train2.copy()\n",
    "#         X_test = X_val.copy()\n",
    "#         y_test = y_val.copy()\n",
    "        \n",
    "#         # Create a PCA object\n",
    "#         pca = PCA(n_components=p)\n",
    "\n",
    "#         # Fit the PCA object to the training data\n",
    "#         pca.fit(X_train)\n",
    "\n",
    "#         # Transform the training data\n",
    "#         X_train = pca.transform(X_train)\n",
    "\n",
    "#         # Transform the test data\n",
    "#         X_test = pca.transform(X_test)\n",
    "\n",
    "#         # Apply LDA\n",
    "#         lda = LDA(n_components=19, tol=1e-5)\n",
    "\n",
    "#         lda.fit(X_train, y_train)\n",
    "\n",
    "#         # Transform the training data\n",
    "#         X_train = lda.transform(X_train)\n",
    "\n",
    "#         # Transform the test data\n",
    "#         X_test = lda.transform(X_test)\n",
    "\n",
    "#         # Import LogisticRegression\n",
    "#         from sklearn.linear_model import LogisticRegression\n",
    "#         from sklearn import metrics\n",
    "\n",
    "#         # Create a logistic regression object\n",
    "#         logreg = LogisticRegression(max_iter=3000, solver='lbfgs', multi_class='multinomial', random_state=0)\n",
    "\n",
    "#         # Train the model using the training sets\n",
    "#         logreg.fit(X_train, y_train)\n",
    "\n",
    "#         # Predict the response for validation set\n",
    "#         y_pred = logreg.predict(X_test)\n",
    "\n",
    "#         # Model Accuracy, how often is the classifier correct?\n",
    "#         print(\"LR Validation Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PCA object\n",
    "pca = PCA(n_components=350)\n",
    "\n",
    "# Fit the PCA object to the training data\n",
    "pca.fit(X_train)\n",
    "\n",
    "# Transform the training data\n",
    "X_train = pca.transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LDA\n",
    "lda = LDA(n_components=19)\n",
    "\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "# Transform the training data\n",
    "X_train = lda.transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test = lda.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7854785478547854\n"
     ]
    }
   ],
   "source": [
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# Create a logistic regression object\n",
    "logreg = LogisticRegression(multi_class='multinomial',solver='newton-cg',max_iter=1000)\n",
    "\n",
    "# Train the model using the training sets\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for validation set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# # Model Accuracy, how often is the classifier correct?\n",
    "print(\"Validation Accuracy:\",metrics.accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Opening the file to write the predictions\n",
    "# file = open('LOF_PCA_LDA_LR.csv', 'w')\n",
    "\n",
    "# # Writing the header\n",
    "# file.write('ID,Category')\n",
    "# for i in range(len(y_pred)):\n",
    "#     file.write('\\n')\n",
    "#     file.write(str(i))\n",
    "#     file.write(',')\n",
    "#     file.write(y_pred[i])\n",
    "\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7623762376237624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, bootstrap=False, max_depth=90, min_samples_leaf=3, min_samples_split=6, n_jobs=-1, random_state=0, verbose=1)\n",
    "\n",
    "# Train the classifier\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the validation set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Opening the file to write the predictions\n",
    "# file = open('RFC_LDA_PCA_LOF.csv', 'w')\n",
    "\n",
    "# # Writing the header\n",
    "# file.write('ID,Category')\n",
    "# for i in range(len(y_pred)):\n",
    "#     file.write('\\n')\n",
    "#     file.write(str(i))\n",
    "#     file.write(',')\n",
    "#     file.write(y_pred[i])\n",
    "\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a Bagging Classifier\n",
    "# from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# # Train the classifier\n",
    "# bag_clf = BaggingClassifier(base_estimator=rf, n_estimators=100, bootstrap=True, n_jobs=-1, random_state=0, verbose=1)\n",
    "\n",
    "# bag_clf.fit(X_train2, y_train2)\n",
    "\n",
    "# # Predict the validation set\n",
    "# y_pred = bag_clf.predict(X_val)\n",
    "\n",
    "# # Calculate the accuracy\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/arnav/Desktop/ML Codes/SML_Project/LOF_PCA_LDA.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/arnav/Desktop/ML%20Codes/SML_Project/LOF_PCA_LDA.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m abc \u001b[39m=\u001b[39m AdaBoostClassifier(base_estimator\u001b[39m=\u001b[39mrf, n_estimators\u001b[39m=\u001b[39m\u001b[39m400\u001b[39m, learning_rate\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/arnav/Desktop/ML%20Codes/SML_Project/LOF_PCA_LDA.ipynb#X30sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Train Adaboost Classifer\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/arnav/Desktop/ML%20Codes/SML_Project/LOF_PCA_LDA.ipynb#X30sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model \u001b[39m=\u001b[39m abc\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnav/Desktop/ML%20Codes/SML_Project/LOF_PCA_LDA.ipynb#X30sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Predict the response for validation set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnav/Desktop/ML%20Codes/SML_Project/LOF_PCA_LDA.ipynb#X30sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:506\u001b[0m, in \u001b[0;36mAdaBoostClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    501\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAlgorithm must be \u001b[39m\u001b[39m'\u001b[39m\u001b[39mSAMME\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mSAMME.R\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    502\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgorithm\u001b[39m!r}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    503\u001b[0m     )\n\u001b[1;32m    505\u001b[0m \u001b[39m# Fit\u001b[39;00m\n\u001b[0;32m--> 506\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, y, sample_weight)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:160\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    156\u001b[0m random_state \u001b[39m=\u001b[39m check_random_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n\u001b[1;32m    158\u001b[0m \u001b[39mfor\u001b[39;00m iboost \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators):\n\u001b[1;32m    159\u001b[0m     \u001b[39m# Boosting step\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     sample_weight, estimator_weight, estimator_error \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_boost(\n\u001b[1;32m    161\u001b[0m         iboost, X, y, sample_weight, random_state\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    164\u001b[0m     \u001b[39m# Early termination\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:568\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[39m\"\"\"Implement a single boost.\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \n\u001b[1;32m    531\u001b[0m \u001b[39mPerform a single boost according to the real multi-class SAMME.R\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[39m    If None then boosting has terminated early.\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgorithm \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSAMME.R\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 568\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_boost_real(iboost, X, y, sample_weight, random_state)\n\u001b[1;32m    570\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# elif self.algorithm == \"SAMME\":\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_boost_discrete(iboost, X, y, sample_weight, random_state)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:579\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    575\u001b[0m estimator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    577\u001b[0m estimator\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight)\n\u001b[0;32m--> 579\u001b[0m y_predict_proba \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[1;32m    581\u001b[0m \u001b[39mif\u001b[39;00m iboost \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    582\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mclasses_\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:885\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    880\u001b[0m all_proba \u001b[39m=\u001b[39m [\n\u001b[1;32m    881\u001b[0m     np\u001b[39m.\u001b[39mzeros((X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], j), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m    882\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39matleast_1d(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_)\n\u001b[1;32m    883\u001b[0m ]\n\u001b[1;32m    884\u001b[0m lock \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mLock()\n\u001b[0;32m--> 885\u001b[0m Parallel(n_jobs\u001b[39m=\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, require\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msharedmem\u001b[39;49m\u001b[39m\"\u001b[39;49m)(\n\u001b[1;32m    886\u001b[0m     delayed(_accumulate_prediction)(e\u001b[39m.\u001b[39;49mpredict_proba, X, all_proba, lock)\n\u001b[1;32m    887\u001b[0m     \u001b[39mfor\u001b[39;49;00m e \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimators_\n\u001b[1;32m    888\u001b[0m )\n\u001b[1;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m proba \u001b[39min\u001b[39;00m all_proba:\n\u001b[1;32m    891\u001b[0m     proba \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    766\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py:600\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    598\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 600\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    601\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import ADA Boosting Classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Create adaboost classifer object\n",
    "abc = AdaBoostClassifier(base_estimator=rf, n_estimators=400, learning_rate=0.01, random_state=0)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "model = abc.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for validation set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Validation Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n",
    "\n",
    "# # Opening the file to write the predictions\n",
    "# file = open('LOF_RFC_ADA.csv', 'w')\n",
    "\n",
    "# # Writing the header\n",
    "# file.write('ID,Category')\n",
    "# for i in range(len(y_pred)):\n",
    "#     file.write('\\n')\n",
    "#     file.write(str(i))\n",
    "#     file.write(',')\n",
    "#     file.write(y_pred[i])\n",
    "\n",
    "# file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    1.0s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/arnav/Desktop/ML Codes/SML_Project/LOF_PCA_LDA.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnav/Desktop/ML%20Codes/SML_Project/LOF_PCA_LDA.ipynb#X31sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m model \u001b[39m=\u001b[39m StackingClassifier(estimators\u001b[39m=\u001b[39mlevel0, final_estimator\u001b[39m=\u001b[39mlevel1, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, passthrough\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnav/Desktop/ML%20Codes/SML_Project/LOF_PCA_LDA.ipynb#X31sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# fit the model on all available data\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/arnav/Desktop/ML%20Codes/SML_Project/LOF_PCA_LDA.ipynb#X31sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnav/Desktop/ML%20Codes/SML_Project/LOF_PCA_LDA.ipynb#X31sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Predict the response for validation set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnav/Desktop/ML%20Codes/SML_Project/LOF_PCA_LDA.ipynb#X31sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_stacking.py:584\u001b[0m, in \u001b[0;36mStackingClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_le \u001b[39m=\u001b[39m LabelEncoder()\u001b[39m.\u001b[39mfit(y)\n\u001b[1;32m    583\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_le\u001b[39m.\u001b[39mclasses_\n\u001b[0;32m--> 584\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_le\u001b[39m.\u001b[39;49mtransform(y), sample_weight)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_stacking.py:189\u001b[0m, in \u001b[0;36m_BaseStacking.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mappend(estimator)\n\u001b[1;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     \u001b[39m# Fit the base estimators on the whole training data. Those\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     \u001b[39m# base estimators will be used in transform, predict, and\u001b[39;00m\n\u001b[1;32m    188\u001b[0m     \u001b[39m# predict_proba. They are exposed publicly.\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[1;32m    190\u001b[0m         delayed(_fit_single_estimator)(clone(est), X, y, sample_weight)\n\u001b[1;32m    191\u001b[0m         \u001b[39mfor\u001b[39;49;00m est \u001b[39min\u001b[39;49;00m all_estimators\n\u001b[1;32m    192\u001b[0m         \u001b[39mif\u001b[39;49;00m est \u001b[39m!=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mdrop\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    193\u001b[0m     )\n\u001b[1;32m    195\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnamed_estimators_ \u001b[39m=\u001b[39m Bunch()\n\u001b[1;32m    196\u001b[0m est_fitted_idx \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:440\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 440\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    442\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    443\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import Stack Classifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# define the base models\n",
    "level0 = list()\n",
    "\n",
    "level0.append(('logreg', logreg))\n",
    "level0.append(('rf', rf))\n",
    "level0.append(('abc', abc))\n",
    "\n",
    "# define meta learner model\n",
    "level1 = abc\n",
    "\n",
    "# define the stacking ensemble\n",
    "model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5, n_jobs=-1, passthrough=True)\n",
    "\n",
    "# fit the model on all available data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for validation set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Validation Accuracy:\",metrics.accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the file to write the predictions\n",
    "file = open('StackClassifier.csv', 'w')\n",
    "\n",
    "# Writing the header\n",
    "file.write('ID,Category')\n",
    "for i in range(len(y_pred)):\n",
    "    file.write('\\n')\n",
    "    file.write(str(i))\n",
    "    file.write(',')\n",
    "    file.write(y_pred[i])\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create a Gradient Boosting Classifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# # Create a Gradient Boosting model\n",
    "# gb = GradientBoostingClassifier(n_estimators=400, learning_rate=0.01, max_depth=3, random_state=0, verbose=1)\n",
    "\n",
    "# # Fit the model to the training data\n",
    "# gb.fit(X_train, y_train)\n",
    "\n",
    "# #Predict the labels of the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = gb.predict(X_test)\n",
    "\n",
    "# # Calculate the accuracy of the model\n",
    "# accuracy = np.sum(y_pred == y_val) / len(y_val)\n",
    "\n",
    "# print('Validation Accuracy: ', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
