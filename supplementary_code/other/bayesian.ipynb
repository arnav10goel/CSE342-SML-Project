{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     C     |\n",
      "-------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.8074   \u001b[0m | \u001b[0m3.745e+04\u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.8033   \u001b[0m | \u001b[0m9.507e+04\u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.8033   \u001b[0m | \u001b[0m7.32e+04 \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.8033   \u001b[0m | \u001b[0m5.987e+04\u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.8033   \u001b[0m | \u001b[0m1.56e+04 \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.8074   \u001b[0m | \u001b[0m3.745e+04\u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.8074   \u001b[0m | \u001b[0m4.461e+04\u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.8033   \u001b[0m | \u001b[0m4.812    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.8074   \u001b[0m | \u001b[0m3.051e+04\u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.8074   \u001b[0m | \u001b[0m4.14e+04 \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.8074   \u001b[0m | \u001b[0m3.347e+04\u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.8074   \u001b[0m | \u001b[0m4.804e+04\u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.8074   \u001b[0m | \u001b[0m2.677e+04\u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.8074   \u001b[0m | \u001b[0m2.836e+04\u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.8074   \u001b[0m | \u001b[0m4.656e+04\u001b[0m |\n",
      "=====================================\n",
      "Best hyperparameters: {'target': 0.8073770491803278, 'params': {'C': 37454.01188536171}}\n",
      "Accuracy: 0.8073770491803278\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# Step 1: Load the data\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Drop the ID column\n",
    "data = data.drop('ID', axis=1)\n",
    "\n",
    "# Step 2: Split the data into features and target variable\n",
    "X = data.drop('category', axis=1)\n",
    "y = data['category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Step 3: Detect and remove outliers using LOF\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "lof = LocalOutlierFactor(n_neighbors=9)\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "# Step 4a: Preprocess the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Step 5: Choose a machine learning algorithm\n",
    "def fit_logreg(C):\n",
    "    clf = LogisticRegression(C=C, max_iter=1000)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Step 6: Define the parameter bounds for Bayesian optimization\n",
    "pbounds = {'C': (0.000001, 100000)}\n",
    "\n",
    "# Step 7: Run Bayesian optimization to find the best hyperparameters\n",
    "optimizer = BayesianOptimization(\n",
    "    f=fit_logreg,\n",
    "    pbounds=pbounds,\n",
    "    random_state=42\n",
    ")\n",
    "optimizer.maximize(init_points=5, n_iter=10)\n",
    "\n",
    "print(\"Best hyperparameters:\", optimizer.max)\n",
    "\n",
    "clf = LogisticRegression(C=optimizer.max['params']['C'], max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Test the model's performance on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "# print(\"Confusion matrix:\")\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Step 9: Save the predictions to a file using the trained models\n",
    "clf2 = LogisticRegression(C=optimizer.max['params']['C'], max_iter=1000)\n",
    "clf2.fit(X, y)\n",
    "test_df = pd.read_csv('test.csv')\n",
    "# drop the ID column\n",
    "test_df = test_df.drop('ID', axis=1)\n",
    "X_test = scaler.transform(test_df)\n",
    "y_pred = clf.predict(X_test)\n",
    "test_df['category'] = y_pred\n",
    "file = open('bayesian.csv', 'w')\n",
    "# Writing the header\n",
    "file.write('ID,Category')\n",
    "for i in range(len(y_pred)):\n",
    "    file.write('\\n')\n",
    "    file.write(str(i))\n",
    "    file.write(',')\n",
    "    file.write(y_pred[i])\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
